{"cells":[{"cell_type":"markdown","metadata":{"id":"7lf2XaewzbE7"},"source":["##**Flow Rate Profile Analysis**\n","Feb 2022 - Lane Breshears, modified from .py code Alex Day\n","\n","Use with any microfluidic chip, place the black line over the channel to analyze flow across the channel. Specify number of channels and channel gaps.\n"]},{"cell_type":"markdown","metadata":{"id":"2HtCMU7y0-Fc"},"source":["## Setup"]},{"cell_type":"markdown","metadata":{"id":"DCb5X55L0ffm"},"source":["**Link CoLab code with your Google Drive**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26418,"status":"ok","timestamp":1684345962345,"user":{"displayName":"Chloe Lauren Thomas","userId":"01729028628246386917"},"user_tz":420},"id":"mXYJiQrWq4H5","outputId":"1ad5605d-1a85-46f0-d252-8a3334bff555"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# https://drive.google.com/drive/folders/1FWndAYiDDbhP_JWq7UcodWYYF2mCsjqb?usp=sharing"]},{"cell_type":"markdown","metadata":{"id":"NIzL6gLXTrFd"},"source":["**Link CoLab code with Google Sheets**"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ttH9ImrK1xP8","executionInfo":{"status":"ok","timestamp":1684345981650,"user_tz":420,"elapsed":12650,"user":{"displayName":"Chloe Lauren Thomas","userId":"01729028628246386917"}}},"outputs":[],"source":["from google.colab import auth\n","auth.authenticate_user()\n","\n","import gspread\n","from google.auth import default\n","creds, _ = default()\n","\n","gc = gspread.authorize(creds)"]},{"cell_type":"markdown","metadata":{"id":"0jfyOYpwzZ6q"},"source":["**Open the active folder with videos**"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":871,"status":"ok","timestamp":1684345985907,"user":{"displayName":"Chloe Lauren Thomas","userId":"01729028628246386917"},"user_tz":420},"id":"v9Wb_lK8q_SK","outputId":"0168727c-2e3d-40bb-c1fd-8618b584b74a"},"outputs":[{"output_type":"stream","name":"stdout","text":[" 20221128_115608.mp4  'test bounds.png'\n"]}],"source":["# Change the below to open up the folder that has the videos in it\n","!ls '/content/drive/MyDrive/PFAS_Project/videos/chipdip_prototype'"]},{"cell_type":"markdown","metadata":{"id":"DG_IkLO92EZa"},"source":["**Import Libraries**"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"c5HZulND2NZa","executionInfo":{"status":"ok","timestamp":1684346004103,"user_tz":420,"elapsed":5180,"user":{"displayName":"Chloe Lauren Thomas","userId":"01729028628246386917"}}},"outputs":[],"source":["from tensorflow.python.util.tf_export import get_canonical_name_for_symbol\n","import numpy as np\n","import cv2\n","import os\n","import csv\n","import matplotlib.pyplot as plt\n","import sys\n","from google.colab.patches import cv2_imshow #to see images, can be deleted later\n","import pandas as pd\n","\n","import gspread_dataframe as gd\n","import gspread as gs"]},{"cell_type":"markdown","metadata":{"id":"eaRYM3_U11Hp"},"source":["# Analyze videos"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"TDIQT24ZqtQC","colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"status":"error","timestamp":1684352395803,"user_tz":420,"elapsed":3023,"user":{"displayName":"Chloe Lauren Thomas","userId":"01729028628246386917"}},"outputId":"2b3fe5ac-5c4f-41b6-89ad-240ae51e568f"},"outputs":[{"output_type":"stream","name":"stdout","text":["845\n","20221128_115608.mp4\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-e7386b16c5e1>\u001b[0m in \u001b[0;36m<cell line: 143>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel_location\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#1st thing to happen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mexampleBounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideoName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m                 \u001b[0mflowProfile_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflowAnalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideoName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0mdf_flowProfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflowProfile_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-26-e7386b16c5e1>\u001b[0m in \u001b[0;36mexampleBounds\u001b[0;34m(videoName, location, start, end, axes)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#or this may be the crux of the cookie actually I think not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#added for testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# converts image from one color space to another \"image\" to gray scale image named \"gray\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlaneLength\u001b[0m\u001b[0;34m:\u001b[0m            \u001b[0;31m#creates the gray lines using iteravite process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: cv2_imshow() takes 1 positional argument but 2 were given"]}],"source":["def createSpreadsheet(videoName):\n","\t'''\n","\tvideoName = the name of the video being analyzed will be \n","\tused to create the worksheet\n","\t'''\n","\tgc = gspread.authorize(creds)\n","\tsh = gc.create(str(videoName))\n","\tprint(videoName)\n","\treturn sh\n","\n","def defineLane(start, end):\n","\t'''\n","\tAuxilliary function used to correctly determine which pixels to look at in the lane, regardless of whether the pixel \n","\tnumbers go from high to low or low to high\n","\t'''\n","\tpoints = []\n","\ttemp = end - start\n","\tif temp < 0:\n","\t\tfor i in range(end, start):\n","\t\t\tpoints.append(i)\n","\telse:\n","\t\tfor i in range(start, end):\n","\t\t\tpoints.append(i)\n","\treturn points\n","\n","def flowAnalysis(videoName, location, start, end, channel, axes, threshold=13):\n","\t'''\n","\tGiven a video file, return a list of the flow profile of the moving front. Each index will represent a frame of the \n","\toriginal video file, and its value will represent how many pixels the wetting front has flowed through\n","\n","\tParameters:\n","\t\"videoName\" = the file name of the video file\n","\t\"Location\" = if the axis is horizontal, then location is the pixel row containing the desired lane, while if the\n","\t\t\t\t axis vertical, then location is the pixel column contained the desired lane\n","\t\"start\" = the starting pixel in the row/column (dictated by \"Location\" parameter) of the desired lane\n","\t\"end\" = the ending pixel in the row/column (dictated by the \"Location\" parameter) of the desired lane\n","\t\"axes\" = determines whether the desired flow lane is horizontal or vertical in the video file (MUST BE EITHER \"H\" OR \"V\")\n","\t\"channel\" = the channel number on the chip\n","\t'''\n","\t\n","\t# NOTE: if you're not seeing any movement in your data, change this threshold value! It represents the brightness change\n","\t# in a pixel within the flow lane that is considered to be high enough to conclude that the moving front has moved to\n","\t# that location. \n","\tthreshold = threshold\n","\n","\tpossibleAxes = ['H', 'V']\n","\tif axes not in possibleAxes:\n","\t\tprint('Axes parameter not allowed, must be either H or V')\n","\t\tsys.exit()\n","\tlaneLength = defineLane(start, end)\n","\n","\tflowProfile = []\n","\tvideo = cv2.VideoCapture(videoName)\n","\tprint('Video name: {}'.format(videoName))  #4th thing to happen \n","\tprint('Video length (frames): {}'.format(video.get(cv2.CAP_PROP_FRAME_COUNT))) #5th thing to happen \n","\tsuccess = True\n","\timageNumber = 1\n","\twhile success:\n","\t\t# print('Image Number: {}'.format(imageNumber))\n","\t\tsuccess, image = video.read()\n","\t\tif success:\n","\t\t\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\t\t\tif imageNumber == 1:\n","\t\t\t\tinitialLane = []\n","\t\t\t\tfor i in laneLength:\n","\t\t\t\t\ttriplet = []\n","\t\t\t\t\tfor j in range(-1, 2):\n","\t\t\t\t\t\tif axes == 'H':\n","\t\t\t\t\t\t\ttriplet.append(gray[location + j, i])\n","\t\t\t\t\t\telif axes == 'V':\n","\t\t\t\t\t\t\ttriplet.append(gray[i, location + j])\n","\t\t\t\t\tinitialLane.append(np.average(triplet))\n","\n","\t\t\tcurrentLane = []\n","\t\t\tdifferences = 0\n","\t\t\tfor i in laneLength:\n","\t\t\t\ttriplet = []\n","\t\t\t\tfor j in range(-1, 2):\n","\t\t\t\t\tif axes == 'H':\n","\t\t\t\t\t\t\ttriplet.append(gray[location + j, i])\n","\t\t\t\t\telif axes == 'V':\n","\t\t\t\t\t\ttriplet.append(gray[i, location + j])\n","\t\t\t\tcurrentLane.append(np.average(triplet))\n","\n","\t\t\tfor i in range(0, len(laneLength)):\n","\t\t\t\tdifference = initialLane[i] - currentLane[i]\n","\t\t\t\tif difference >= threshold:\n","\t\t\t\t\tdifferences += 1\n","\n","\t\t\tflowProfile.append(differences)\n","\t\t\timageNumber += 1\n","\n","\n","\t\n","\tprint('Maximum flow (pixels): {}'.format(np.amax(flowProfile)))\n","\tvideoFPS = video.get(cv2.CAP_PROP_FPS)\n","\tprint('VIDEO FPS IS:')\n","\tprint(videoFPS)\n","\tvideoDuration = int(video.get(cv2.CAP_PROP_FRAME_COUNT)) / videoFPS\n","\tprint('Total Velocity: {:2f}'.format(float(np.amax(flowProfile) / videoDuration)))\n","\tprint('------------------')\n","\n","\tplt.figure()\n","\tplt.suptitle('Flow Profile (Pixels vs. Frame Number)')\n","\tplt.plot(flowProfile)\n","\tplt.show()\n","\treturn flowProfile\n","\n","def exampleBounds(videoName, location, start, end, axes='H'):\n","\t'''\n","\tGiven a video file, the function will save a grayscale image depicting where the analysis algorithm would consider\n","\tthe lane to be (by using a solid black line over the first frame of the video)\n","\n","\tParameters:\n","\t\"videoName\" = the file name of the video file\n","\t\"Location\" = if the axis is horizontal, then location is the pixel row containing the desired lane, while if the\n","\t\t\t\t axis vertical, then location is the pixel column contained the desired lane\n","\t\"start\" = the starting pixel in the row/column (dictated by \"Location\" parameter) of the desired lane\n","\t\"end\" = the ending pixel in the row/column (dictated by the \"Location\" parameter) of the desired lane\n","\t\"axes\" = determines whether the desired flow lane is horizontal or vertical in the video file (MUST BE EITHER \"H\" OR \"V\")\n","\t'''\n","\tpossibleAxes = ['H', 'V']\n","\tif axes not in possibleAxes:\n","\t\tprint('Axes parameter not allowed, must be either H or V')\n","\t\tsys.exit()\n","\tlaneLength = defineLane(start, end)  #uses auxilary function defineLane\n","\tvideo = cv2.VideoCapture(videoName)  #reads video file from path, still a video file I believe\n","\t#cv2_imshow(video) #added for testing, didn't work with this line\n","\tprint(videoName) #2nd thing to happen\n","\tsuccess = True\n","\tsuccess, image = video.read() #or this may be the crux of the cookie actually I think not\n","\tcv2_imshow(image, 300)  #added for testing\n","\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # converts image from one color space to another \"image\" to gray scale image named \"gray\"\n","\tfor i in laneLength:\t\t#creates the gray lines using iteravite process\n","\t\tif axes == 'H':\n","\t\t\tgray[location, i] = 0 #changes pixel color at specified points 0: black 255: white\n","\t\telif axes == 'V':\n","\t\t\tgray[i, location] = 0 #changes pixel color at specified points 0: black 255: white\n","\tcv2.imwrite('test bounds.png', gray)  #saves image to specified file \n","\tcv2_imshow(gray) #shows the image below. 3rd thing to happen\n","\n","\n","if __name__ == '__main__':\n","\n","\t#EDITABLE FOR DATA COLLECTION \n","\tos.chdir(os.path.join(r'/content/drive/MyDrive/PFAS_Project/videos/chipdip_prototype'))  #C:\\Users\\owner\\Downloads'))\n","\n","\n","\tvideoName = '20221128_115608.mp4'\n","\tstart = int(2900) #100 vertical positioning)\n","\tend = int(2100) #510 vertical positioning)\n","\tchannel_gap = int(145) #130 - cellulose jump from channel to chnl in px distance\n","\tlocation1 = int(845) #Row/channel initial position for horizontal chip/Verticla chip would be column (moves horizontally)\n","\tnumberChannels = 4 #5 for cellulose - 4 for covid\n","\taxes = 'V' #H - horizontal, V - vertical\n","\t#Save the data to google sheets\n","\tgc = gspread.authorize(creds)\n","\tsh = gc.create(str(videoName))\n","\t\n","\t#END OF EDITABLE\n","\t\n","\n","\tfor i in list(range(0,numberChannels)):   #code \"starts\" here\n","\t\tchannel = i + 1\n","\t\tif axes == 'H':\n","\t\t\tchannel_location = location1 - channel_gap*(i) #assuming 1st channel is on bottom of chip\n","\t\telif axes == 'V':\n","\t\t\tchannel_location = location1 + channel_gap*(i) #assuming 1st channel is on far left of chip\n","\t\telse:\n","\t\t\tprint('Check which channel you are starting on')\n","\t \n","\t\tprint(channel_location)  #1st thing to happen\n","\t\texampleBounds(videoName, channel_location, start, end, axes) \n","\t\tflowProfile_list = flowAnalysis(videoName, channel_location, start, end, i, axes, threshold=9)\n","\t\tdf_flowProfile = pd.DataFrame(flowProfile_list)\n","\t\t\n","\t\tws = sh.add_worksheet(title=str(channel), rows=\"100\", cols=\"20\")\n","\t\tws = gc.open(str(videoName)).worksheet(str(channel))\n","\t\tgd.set_with_dataframe(ws, df_flowProfile)\n","\n","\tws = sh.get_worksheet(0)\n","\ta=range(len(df_flowProfile)+1)\n","\tarray = np.array([a]).T\n","\t# Write the frame col to the worksheet starting from the A1 cell\n","\tws.update('A1', array.tolist())\n"]},{"cell_type":"markdown","metadata":{"id":"parNWGfmTFs1"},"source":["Check your data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":154,"status":"ok","timestamp":1684191739118,"user":{"displayName":"Chloe Lauren Thomas","userId":"01729028628246386917"},"user_tz":420},"id":"A_Z8jyAPTBvv","outputId":"f35f502f-d37f-4b75-9e68-c45360eb7a50"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n#Click to go directly to the data collection spreadsheet of the video analyzed - use latest version and make sure it has all the data\\n#Each sheet is a channel\\n\\nGo to https://sheets.google.com to see your new spreadsheet\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}],"source":["'''\n","#Click to go directly to the data collection spreadsheet of the video analyzed - use latest version and make sure it has all the data\n","#Each sheet is a channel\n","\n","Go to https://sheets.google.com to see your new spreadsheet\n","'''"]}],"metadata":{"colab":{"provenance":[{"file_id":"16ytiELUX_ObbAp-Op1ocIiDhwGpCqWfm","timestamp":1675968010654}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}